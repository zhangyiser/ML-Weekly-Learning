时间：2019年6月17日 ~ 2019年6月23日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
333 | 1.学习 python基础  2.学习吴恩达机器学习入门课程  3.学习SQL语句| 已经自己套用别人写过的模型完成了一些工作，但是发现如果还要更进一步的话，还是要更熟练得掌握python，it is very important to get familiar with python。 学习资料用的都是星球大大分享的！
杨建民 | 精读《统计学习方法》的第1章和第2章|学习笔记：https://app.yinxiang.com/fx/acea2b7d-9f11-490f-bcc8-8224f196c4d1 https://app.yinxiang.com/fx/64e2f8ae-d926-4f1b-abb5-3b72307a6d1a
具信 |复习《普林斯顿微积分读本》 1- 9 章  | 巩固数学基础，主要复习以下内容：1.函数的基本概念（定义、区间、奇偶性等） 2.函数的基本操作（利用图像、求极限、连续性、导数等） 3.几种常见函数（重点是三角函数、多项式、指数函数、对数函数以及以e为底的函数）以及它们的法则（极限、等式、不等式、导数等公式）
李小川 | numpy复习 +加权线性回归复习+ 集成方法学习 | 这周的学习比较零散，起初是学习集成方法算法模型，原理是比较简单易理解的，主要分为两种：1、投票选举(bagging: 自举汇聚法 bootstrap aggregating): 是基于数据随机重抽样分类器构造的方法 2、再学习(boosting): 是基于所有分类器的加权求和的方法 。前者的算法模型常用的是随机森林，后者常用算法为AdaBoost。但是在算法实现的过程中，发现numpy 和 pandas的运用还是不够灵活，于是重新看了下numpy的教程。后续的主要打算是先跳过这一节内容，先复习一下线性回归，下周再继续攻下集成方法学习。
张弈 | 学习SVM | 之前有大概了解了SVM基本原理，这周比较系统地学习了SVM。对于线性可分支持向量机的最优化问题，应用拉格朗日对偶性可以求得最优解；在函数间隔加上松弛变量来求解训练数据集线性不可分的凸二次规划问题；对于非线性支持向量机的最优化问题，首先使用核函数将原空间的数据映射到新空间，即将非线性问题变成线性问题，再用线性分类学习方法从训练数据中学习分类模型；利用SMO算法求解凸二次规划的对偶问题。
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
